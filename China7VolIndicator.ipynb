{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author：F.T Weng\n",
    "# Purpose： Example of using xgboost to calculate Shapley value, China | 7 days |Indicator\n",
    "# Email: xmftweng@163.com\n",
    "# Import necessary packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# !pip install shap\n",
    "# !pip install xgboost\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of dataset\n",
    "path = '../dataset/sevenVol.csv'\n",
    "lookback_window = 7  # time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the characteristic matrix and label, calculate the effect value, and do not divide the training and test sets\n",
    "# If it needs to be modified,  train_test_split() method can be used.\n",
    "def get_data(path, lookback_window):\n",
    "    \"\"\"\n",
    "    :param path: Data path\n",
    "    :param lookback_window: Prediction step, that is, how many days ago the data is used to predict future data\n",
    "    :return: Feature matrix and label\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "\n",
    "    china_name = ['date','china_vol','Credit','Equity valuation','Safe assets','Funding','Volatility']\n",
    "    china_data = df.loc[:, china_name]\n",
    "\n",
    "    data = china_data.values\n",
    "    input_data = data[:, 1:]  \n",
    "\n",
    "    label = input_data[:, 0]  # label\n",
    "    x, y = [], []\n",
    "    for i in range(lookback_window, len(label)):\n",
    "        # print(i)\n",
    "        x.append(input_data[i - lookback_window:i])\n",
    "        y.append(label[i])\n",
    "    x = np.array(x) \n",
    "    y = np.array(y)   \n",
    "\n",
    "    X = x.reshape(len(x), np.shape(x)[1] * np.shape(x)[2])\n",
    "    Y = y.reshape(-1, 1)  # Convert array dimensions\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1713, 42)\n",
      "(1713, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data(path, lookback_window)\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "# this is also applicable to other models, such as SVR, SGD, RF etc.\n",
    "model = xgb.train({'objective': 'reg:squarederror'}, xgb.DMatrix(X, label=Y), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1713, 42)\n"
     ]
    }
   ],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "print(np.shape(shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009562194"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.expected_value # base value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the shapley value\n",
    "df = pd.read_csv(path, low_memory=False)\n",
    "date = df.loc[lookback_window:, ['date']]\n",
    "SHAP = shap_values\n",
    "all_data = np.hstack((date.values, SHAP)) \n",
    "my_shape = pd.DataFrame(all_data)\n",
    "my_shape.columns =  ['date','volT7','CreditT7','EquityValuationT7','SafeAssetsT7','FundingT7','VolatilityT7',\n",
    "                            'volT6','CreditT6','EquityValuationT6','SafeAssetsT6','FundingT6','VolatilityT6',\n",
    "                            'volT5','CreditT5','EquityValuationT5','SafeAssetsT5','FundingT5','VolatilityT5',\n",
    "                            'volT4','CreditT4','EquityValuationT4','SafeAssetsT4','FundingT4','VolatilityT4',\n",
    "                            'volT3','CreditT3','EquityValuationT3','SafeAssetsT3','FundingT3','VolatilityT3',\n",
    "                            'volT2','CreditT2','EquityValuationT2','SafeAssetsT2','FundingT2','VolatilityT2',\n",
    "                            'volT1','CreditT1','EquityValuationT1','SafeAssetsT1','FundingT1','VolatilityT1']\n",
    "my_shape.to_csv('../result/China7Vol_indicator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
